# Домашнее задание к занятию «Установка Kubernetes»

### Цель задания

Установить кластер K8s.

### Чеклист готовности к домашнему заданию

1. Развёрнутые ВМ с ОС Ubuntu 20.04-lts.


### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания

1. [Инструкция по установке kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/).
2. [Документация kubespray](https://kubespray.io/).

-----

### Задание 1. Установить кластер k8s с 1 master node

1. Подготовка работы кластера из 5 нод: 1 мастер и 4 рабочие ноды.

Кластер готовим в Яндекс облаке. Наиболее оптимальным вариантом будет развернуть виртуальные машины через терраформ, чтобы в случае технических проблем (неправильный расчет вычислительных ресурсов или необходимость изменения количества нод) обеспечить возможность быстрых изменений.

Основной манифест `main.tf` описывает создание 5 виртуальных машин, из которых 4 имеют идентичные параметры (под worker ноды)
```tf
resource "yandex_compute_instance" "control-plane" {
  name            = var.control_plane_name
  platform_id     = var.platform
  resources {
    cores         = var.control_plane_core
    memory        = var.control_plane_memory
    core_fraction = var.control_plane_core_fraction
  }

  boot_disk {
    initialize_params {
      image_id = var.image_id
      size     = var.control_plane_disk_size
    }
  }

  scheduling_policy {
    preemptible = var.scheduling_policy
  }

  network_interface {
    subnet_id = var.subnet_id
    nat       = var.nat
  }

  metadata = {
    user-data = "${file("/home/leo/kuber-homeworks/3.2/terraform/cloud-init-control-plane.yaml")}"
 }
}

resource "yandex_compute_instance" "worker" {
  count           = var.worker_count
  name            = "worker-node-${count.index + 1}"
  platform_id     = var.worker_platform
  resources {
    cores         = var.worker_cores
    memory        = var.worker_memory
    core_fraction = var.worker_core_fraction
  }

  boot_disk {
    initialize_params {
      image_id = var.image_id
      size     = var.worker_disk_size
    }
  }

    scheduling_policy {
    preemptible = var.scheduling_policy
  }

  network_interface {
    subnet_id = var.subnet_id
    nat       = var.nat
  }
  metadata = {
    user-data = "${file("/home/leo/kuber-homeworks/3.2/terraform/cloud-init-worker.yaml")}"
 }
}
```

Основные пользовательские параметры пропишем через в файле `cloud-init.yaml`. Так как для `contro-plane` и `worker` требуются разные пакеты, то целесообразно подготовить отдельные файлы для каждого типа нод.

`cloud-init-control-plane.yaml`
```yml
#cloud-config
users:
  - default
  - name: leo
    ssh_authorized_keys:
      - ssh-rsa 
    sudo: ['ALL=(ALL) NOPASSWD:ALL']
    groups: sudo
    shell: /bin/bash
packages:
  - nginx
  - nano
package_update: true
runcmd:
  - apt-get update
  - apt-get install -y software-properties-common
  - add-apt-repository -y ppa:deadsnakes/ppa
  - apt-get update
  - apt-get install -y python3.11 python3.11-venv python3.11-dev
  - apt-get install -y python3-pip
  - pip3 install --upgrade pip
  - pip3 install ansible>=2.14.0
```

`cloud-init-control-plane.yaml`
```yml
#cloud-config
users:
  - default
  - name: leo
    ssh_authorized_keys:
      - ssh-rsa 
    sudo: ['ALL=(ALL) NOPASSWD:ALL']
    groups: sudo
    shell: /bin/bash
packages:
  - nginx
  - nano
package_update: true
runcmd:
  - apt-get update
  - apt-get install -y software-properties-common
  - add-apt-repository -y ppa:deadsnakes/ppa
  - apt-get update
  - apt-get install -y python3.11 python3.11-venv python3.11-dev
  - apt-get install -y python3-pip
```
Далее привожу ссылки на прочие файлы, необходимые для корректной работы манифеста:

[variables.tf]()

[providers.tf]()

Поднимаем инфраструктуру
```
terraform init
terraform plan
terraform apply
```
![Alt_text]()


2. В качестве CRI — containerd.
3. Запуск etcd производить на мастере.
4. Способ установки выбрать самостоятельно.

## Дополнительные задания (со звёздочкой)

**Настоятельно рекомендуем выполнять все задания под звёздочкой.** Их выполнение поможет глубже разобраться в материале.   
Задания под звёздочкой необязательные к выполнению и не повлияют на получение зачёта по этому домашнему заданию. 

------
### Задание 2*. Установить HA кластер

1. Установить кластер в режиме HA.
2. Использовать нечётное количество Master-node.
3. Для cluster ip использовать keepalived или другой способ.

### Правила приёма работы

1. Домашняя работа оформляется в своем Git-репозитории в файле README.md. Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
2. Файл README.md должен содержать скриншоты вывода необходимых команд `kubectl get nodes`, а также скриншоты результатов.
3. Репозиторий должен содержать тексты манифестов или ссылки на них в файле README.md.
