# Домашнее задание к занятию «Компоненты Kubernetes» - Леонид Хорошев

### Цель задания

Рассчитать требования к кластеру под проект

------

### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания:

- [Considerations for large clusters](https://kubernetes.io/docs/setup/best-practices/cluster-large/),
- [Architecting Kubernetes clusters — choosing a worker node size](https://learnk8s.io/kubernetes-node-size).

------

### Задание. Необходимо определить требуемые ресурсы
Известно, что проекту нужны база данных, система кеширования, а само приложение состоит из бекенда и фронтенда. Опишите, какие ресурсы нужны, если известно:

1. Необходимо упаковать приложение в чарт для деплоя в разные окружения. 
2. База данных должна быть отказоустойчивой. Потребляет 4 ГБ ОЗУ в работе, 1 ядро. 3 копии. 
3. Кеш должен быть отказоустойчивый. Потребляет 4 ГБ ОЗУ в работе, 1 ядро. 3 копии. 
4. Фронтенд обрабатывает внешние запросы быстро, отдавая статику. Потребляет не более 50 МБ ОЗУ на каждый экземпляр, 0.2 ядра. 5 копий. 
5. Бекенд потребляет 600 МБ ОЗУ и по 1 ядру на копию. 10 копий.

### Решение

В решении задачи помимо требований, озвученных в задании будем руководствоваться также целесообразностью расхода ресурсов (экономической составляющей), так как очевидно, что кластер из 50 нод определенно отказоустойчивее кластера из 3 нод, но любой ресурс имеет свою стоимость. 

Сначала рассморим минимально возможный вариант, и запишем его в сводную таблицу

|Компонент|	RAM на копию|	CPU на копию|	Количество копий|	Суммарно RAM и CPU |
|---------|-------------|-------------|-----------------|--------------------|
|База данных|	4 ГБ	|1 ядро|	3 реплики	|12 ГБ	3 ядра |
|Система кеширования|	4 ГБ	|1 ядро|	3 реплики |	12 ГБ	3 ядра|
|Фронтенд|	50 МБ|	0.2 ядра|	5 реплик|	0.25 ГБ	1 ядро |
| Бекенд |	600 МБ	| 1 ядро |	10 реплик |	6 ГБ	10 ядер |

Итого, суммарные ресурсы, необходимые для работы нашего приложения:
- 30,25 ГБ оперативной памяти;
- 10 ядер CPU.

Теперь необходимо определить количество нод, необходимое для такой нагрузки.

Пусть в наш кластер будет устроен следующим образом - одна мастер нода (обеспечивает работу основных компонентов k8s и управляет целиком кластером) и несколько рабочих нод. Ресурсы, посчитанные в предыдущем пункте необходимо использовать только на рабочих нодах. Для обеспечения сохранности данных каждая реплика базы данных должна быть запущена своей ноде, следовательно для базы данных их будет три.

Тоже самое и для системы кеширования - минимальное количество нод - три. Но на каждой ноде можно одновременно запускать как реплику базы данных, так и системы кеширования, итого имеем три ноды следующей минимально возможной конфигурации:
- 8 ГБ RAM;
- 2 ядра CPU.

Фронтенд и бекэнд также можно объединить и запускать по несколько реплик на каждой ноде. Чтобы упростить архитектуру (что может быть полезно при автоматизации развертывания инфраструктуры, например через terraform), мы можем задать конфигурацию ноды, по параметрам аналогичную рассчитанной ранее (8 ГБ RAM и 2 ядра CPU), тогда нам будет необходимо еще 5 нод.

Итого имеем 7 нод конфигурации:
- 8 ГБ RAM;
- 2 ядра CPU.

Не стоит забывать, что помимо наших сервисов на ноде будет также запущен k8s, какой-нибудь container runtime interface (Docker например),  веб сервер (nginx) а также элементы мониторинга (Zabbix агент для мониторинга физических ресурсов и filebeat для обработки информации о логах), следовательно нам требуется увеличить ресурсы минимум вдвое, следовательно рекомендуемые параметры для наших семи нод будут следующие:
- 16 ГБ RAM;
- 4 ядра CPU.

Раз мы вспомнили про монитоиинг, то нам понадобится отдельная виртуальная машина для установки систем мониторинга, поскольку стек ELK крайне требователен к ресурсам (насколько я помню из практики для его стабильной работы необходимо минимум 8 ГБ RAM и 2 ядра CPU), а Zabbix судя по информации из открытых источников потребляет примерно 4 ГБ RAM и 2 ядра CPU, то считаю необходимым добавить еще одну ноду аналогичной конфигурации:
- 16 ГБ RAM;
- 4 ядра CPU.

Теперь перходим к мастер-ноде, она должна быть как минимум одна и должна обеспечить работу следующих компоненов k8s:
- API Server -обработка запросов от клиентов и других компонентов;
- etcd - хранение всех данных кластера;
- сontroller manager - управление контроллерами, обеспечивающими текущее состояние кластера;
- scheduler - планирование подов на рабочие ноды.

В открытых источниках под кластер с ресурсоемкостью аналогичного нашему, рекомендуется использовать хост следующей конфигурации:
- 32 ГБ RAM;
- 8 ядер CPU.

Итого наш кластер состоит из одной мастер-ноды (32 ГБ RAM и 8 ядер CPU) и восьми рабочих (worker) нод (16   ГБ RAM и 4 ядер CPU).

Для обеспечения отказоустойчивасти целесообразно использовать 2 мастер-ноды с балансировкой нагрузки между ними. Что касается worker нод, то с учетом того, что их конфигурация взята с небольшим запасом, и если одна из них выйдет из строя, то требуемую нагрузку можно будет распределить между ними, но если например выйдет из строя 2 и более нод, то понядобятся дополнительные. Сколько их необходимо - понять сложно (в зависимости от аварийных отключений), но избыточное резервирование в данном случеае не будет оправдано с экономической точки зрения. Предлагаю в качестве резерва использовать одну полностью незагруженную в нормальном режиме виртуальную машину в конфигурации (16   ГБ RAM и 4 ядер CPU).

### Итоговая конфигурация кластера для нашего приложения:
- 2 мастер-ноды (32 ГБ RAM и 8 ядер CPU);
- 9 worker-нод (16 ГБ RAM и 4 ядер CPU).

В задании ничего не сказано про размеры жестких дисков, думаю что в нашем случае они будут сильно зависеть от базы данных, но точно можно рекомендовать использовать SSD диски для быстрого доступа к данным и скорости развертки подов. Также решения по мониторингу тоже можно корректировать, например вместо Zabbix использовать Prometheus и Grafana, а вместо  стека ELK внедлить Clickhouse и Vector, но данные решения на мой взгляд не приведут к росту требуемых ресурсов.


----

### Правила приёма работы

1. Домашняя работа оформляется в своем Git-репозитории в файле README.md. Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
2. Сначала сделайте расчёт всех необходимых ресурсов.
3. Затем прикиньте количество рабочих нод, которые справятся с такой нагрузкой.
4. Добавьте к полученным цифрам запас, который учитывает выход из строя как минимум одной ноды. 
5. Добавьте служебные ресурсы к нодам. Помните, что для разных типов нод требовния к ресурсам разные. 
6. В результате должно быть указано количество нод и их параметры.

